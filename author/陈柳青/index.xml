<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>陈柳青 | D3Lab</title>
    <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/author/%E9%99%88%E6%9F%B3%E9%9D%92/</link>
      <atom:link href="https://tsangeyan.github.io/TED3Lab-zh.github.io/author/%E9%99%88%E6%9F%B3%E9%9D%92/index.xml" rel="self" type="application/rss+xml" />
    <description>陈柳青</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 23 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://tsangeyan.github.io/TED3Lab-zh.github.io/author/%E9%99%88%E6%9F%B3%E9%9D%92/avatar_hu0b7056f199e946b7c7909a84e1b679c1_6978_270x270_fill_q75_lanczos_center.jpg</url>
      <title>陈柳青</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/author/%E9%99%88%E6%9F%B3%E9%9D%92/</link>
    </image>
    
    <item>
      <title>UI设计稿智能检查与校正</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_3/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_3/</guid>
      <description>&lt;p&gt;UI design lint, UI to code, multimodal feature fusion, object detection&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;UI设计稿零碎图层合并：Imgcook 是阿里巴巴旗下以各种设计稿图像 (Sketch/PSD/静态图片）为原材料烹饪的匠心大厨，通过智能化手段将各种原始设计稿一键生成可维护的 UI 视图代码和逻辑代码。在实际生产设计过程中，为了达到想要的视觉效果，设计师会使用多个零碎图层来表达一个UI组件。这种设计方式会对智能代码生成算法造成干扰，从而影响最终生成代码的质量。为了保证智能代码生成算法能够生成高质量的代码，亟需有着更高设计标准的设计稿，但这必定会增加设计师的工作成本。由此可见，一个用于检测设计稿中存在的零碎图层并将其自动合并为UI组件的智能检查工具，能够有效解决从设计稿为输入的代码生成质量低下的问题。传统的图层合并方法，通常采用人工辅助合并或一些基于启发式的检查规则来判断是否对这些图层进行合并。这类方法过于依赖设计师或开发者的判断，同时对大量图层进行筛选和判断也提高了工作时间成本。目前尚无方法，通过端到端的智能检测算法，自动筛选和合并碎片图层成为UI组件，来提高最终代码生成的质量。本项目与阿里巴巴智能化前端团队合作，致力于研究智能化端到端的图层合并方法。&lt;/p&gt;
&lt;p&gt;UI设计稿图文同语义成组：随着移动应用程序的普及和发展，图形用户界面（GUI）有着巨大的开发需求。从UI设计稿自动生成UI代码极大地简化了开发流程。但是，设计稿中的嵌套层结构会影响生成代码的质量和可用性。现有的GUI自动化技术很少能检测和分组嵌套层以提高生成代码的可访问性。在本文中，我们提出了一种基于计算机视觉的方法UI Layers Grouper。它可以自动检测呈现相同语义含义的图像（即基本形状和视觉元素）和文本层。我们提出了两个组件，文本融合和框注意力机制，它们利用来自设计稿的文本信息作为先验组定位信息。我们构建了一个用于训练和测试的大规模 UI 数据集，并提出了一种数据增强方法来提高检测性能。实验表明，所提出的方法在层分组方面取得了不错的准确性。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_9ded980b4a5bc6c0b35870890b568003.webp 400w,
               /TED3Lab-zh.github.io/media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_320200b6f7b3845f8f4dbd128cbb0c05.webp 760w,
               /TED3Lab-zh.github.io/media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_9ded980b4a5bc6c0b35870890b568003.webp&#34;
               width=&#34;760&#34;
               height=&#34;371&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>基于结构化知识的仿生设计创意激发工具</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_6/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_6/</guid>
      <description>&lt;p&gt;Bio-inspired design, Design ideation, Information extraction&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;经过数百万年的进化，自然系统中的许多优秀的生物策略可以被利用到一种新的类比设计形式中，即生物启发设计（BID）。尽管BID作为一种设计方法已被证明是有益的，但在生物学和工程学之间存在着差距，因为绝大多数的生物知识都是非结构化的。这种非结构化的生物知识通常以大段的形式呈现。设计者很难快速获取和理解非结构化生物知识中的关键信息。为了解决这个问题，我们提出了一种结构化生物知识的方法，并构建了AsknatureNet：一个基于结构化知识的仿生设计创意激发工具。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_70e177ab67fc5c7e3e6e308480ceac82.webp 400w,
               /TED3Lab-zh.github.io/media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_5b3c8251c8362b6bc80a8ba81c126f72.webp 760w,
               /TED3Lab-zh.github.io/media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_70e177ab67fc5c7e3e6e308480ceac82.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>电商AR新交互新体验探索</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_4/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_4/</guid>
      <description>&lt;p&gt;augmented reality, virtual reality, online shopping, comparison of technologies, 3D / Multimodal user interface&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;随着元宇宙概念的持续升温和社交、生产协作、购物等具体应用场景的逐步构建，各类产业对于扩展现实系列技术的体验设计规范、针对具体场景的技术引入和体验优化等方面的需求正在扩大。另一方面，学界与业界对于虚拟现实、增强现实、混合现实等各类主流元宇宙用户界面技术的基本定义、技术特征、对用户体验的具体影响的共识尚未建立；高维度、多感官通道的扩展现实体验空间的设计空间与设计规范有待拓展；适合扩展现实体验空间的具体设计策略与呈现内容的典型形式、方式有待探索。本项目依托浙江大学与阿里巴巴前端设计委员会合作项目开展，通过扩展现实技术创新电商平台的营销导购方式，实现基于多种扩展现实技术的场景化购物方案和原型设计。项目下辖多个研究小组，在增强现实与虚拟现实技术的用户体验差异、扩展现实场景下的多模态信息呈现技术、面向特殊使用场景的下一代扩展现实技术技术特征等方面做出有力的探索，并结合场景特点提出以场景作为商品配置的货架、以互动塑造商品认知过程、以三维多感官界面重塑界面信息架构的研究思路。相关研究成果可应用于虚拟购物平台三维化营销场景的设计实践，或为一般扩展现实应用的信息与交互设计提供指导。该团队目前参与元宇宙相关主题《信息与交互设计》课程建设及多个本科生科研训练项目过程指导。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_df309c55cf4e9b685b47ad60ad2adfcc.webp 400w,
               /TED3Lab-zh.github.io/media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_efdf3b692817c68c53bca692f1ead846.webp 760w,
               /TED3Lab-zh.github.io/media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_df309c55cf4e9b685b47ad60ad2adfcc.webp&#34;
               width=&#34;760&#34;
               height=&#34;374&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;











&lt;div class=&#34;gallery&#34;&gt;

  
  
  
    
    
    
    
    
    &lt;a data-fancybox=&#34;gallery-project_4&#34; href=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/albums/project_4/1.png&#34; &gt;
      &lt;img src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/albums/project_4/1_hu90bce225f99162c83f1cec892628d724_418761_520x0_resize_q75_h2_lanczos_3.webp&#34; loading=&#34;lazy&#34; alt=&#34;1.png&#34; width=&#34;520&#34; height=&#34;321&#34;&gt;
    &lt;/a&gt;
  
    
    
    
    
    
    &lt;a data-fancybox=&#34;gallery-project_4&#34; href=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/albums/project_4/4.png&#34; &gt;
      &lt;img src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/albums/project_4/4_hu3168de5f82c083371df3b72e366723b7_9510081_520x0_resize_q75_h2_lanczos_3.webp&#34; loading=&#34;lazy&#34; alt=&#34;4.png&#34; width=&#34;520&#34; height=&#34;520&#34;&gt;
    &lt;/a&gt;
  

&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>电商导购场中用户浏览行为意图预测</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_7/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_7/</guid>
      <description>&lt;p&gt;E-commerce, Product recommendation page, Intent prediction, Interest Analysis&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;用户行为数据一直是电商平台决策和提升体验的关键，尤其是在预测用户行为意图时。如今，随着推荐系统的普及，电商导购场(PRP)在电子商务平台中发挥着越来越重要的作用。然而，过去关于跨电子商务平台预测用户行为意图的研究可能不适用于用户具有不同特征的电商导购场。本研究对电商导购场的用户浏览行为意图进行了研究和预测。收集和处理了电商导购场的大量用户数据，并建立了相应的数据集。在此基础上，提出了一种用户兴趣分析方法，并对五种浏览意图预测模型进行了应用和比较。该方法区分了不同浏览兴趣程度的用户，模型能更好地预测用户在不同兴趣群体中的浏览行为意图。在大规模数据集上的验证实验表明，该方法能够较好地预测用户的浏览意图。我们探索人工智能（AI）的最新发展，使用预先训练好的语言模型（PLM）来微调3个模型，并总结出生物知识的关键词。&amp;ldquo;来源&amp;rdquo;、&amp;ldquo;好处 &amp;ldquo;和 &amp;ldquo;应用&amp;rdquo;。我们评估了这些关键词与生物知识的相关性，结果表明，该模型具有与人类相同的概括能力。基于这些关键词，我们构建了一个用于刺激BID构思的语义网络，提出了一个基于语义网络的构思算法，并开发了AsknatureNet。AsknatureNet可以实现解决方案驱动的模式BID和问题驱动的模式BID。每种模式都会产生3种不同程度的结果。通过两个案例研究，我们证明了将该系统用于解决方案驱动的模式BID和问题驱动的模式BID的有效性，并产生了解决问题和开放创新的新设计理念。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_90ded84e83fdb18b7cf7d0bf258a0e13.webp 400w,
               /TED3Lab-zh.github.io/media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_b6cf7780c5cb79821ddda234ff8b7d79.webp 760w,
               /TED3Lab-zh.github.io/media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_90ded84e83fdb18b7cf7d0bf258a0e13.webp&#34;
               width=&#34;760&#34;
               height=&#34;146&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>电商平台中不同购物场景下的布局生成</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_2/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_2/</guid>
      <description>&lt;p&gt;布局生成，深度生成模型，用户界面设计，商品展示页面&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;布局是移动购物应用程序的商品展示页面中至关重要的一部分。为了清楚、准确地传达消费者所需的商品信息，商品展示页面（Product Listing Pages, PLP）的布局设计通常由其购物场景驱动。在这项工作中，我们研究了针对不同场景的布局设计，并提出了一个设计空间来指导PLP的布局生成和评估。此外，我们还提出了一个布局生成模型，LayoutVQ-VAE，该模型以用户输入的布局应用场景和元素类别为约束，能够生成满足约束的高质量布局。LayoutVQ-VAE也可以应用于文档布局、杂志布局、手机UI布局等相关的设计任务中。&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/project/project_2/Layout%20Generation%20for%20Various%20Scenarios%20in%20Mobile%20Shopping%20Apps.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;</description>
    </item>
    
    <item>
      <title>维基智联：基于维基百科的创意激发语义网络</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_5/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_5/</guid>
      <description>&lt;p&gt;Semantic network, Design innovation, Wikipedia, Data-driven design, Data-driven ,innovation&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;数据驱动的设计和创新是一个重新使用和提供有价值和有用信息的过程。然而，现有的用于设计创新的语义网络是建立在仅限于技术和科学信息的数据源上。此外，现有的研究只在统计学或语义学关系上建立语义网络的边缘，这不太可能充分利用这两类关系的好处，发现设计创新的隐性知识。因此，我们构建了WikiLink，一个基于维基百科的语义网络。在WikiLink中引入了融合了概念间统计学和语义学权重的组合权重，并开发了四种算法来激发新的想法。进行了评估实验，结果显示该网络的特点是对术语、关系和学科的高度覆盖，这证明了该网络的有效性和有用性。然后，一个演示和案例研究结果表明，WikiLink可以作为概念设计创新的想法生成工具。WikiLink的源代码和后台数据是开源的，供更多的用户探索和使用。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_f75a847c0fbb640851c3c1f450a96d76.webp 400w,
               /TED3Lab-zh.github.io/media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_165c867c97f947219768745f2ae65d47.webp 760w,
               /TED3Lab-zh.github.io/media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_f75a847c0fbb640851c3c1f450a96d76.webp&#34;
               width=&#34;760&#34;
               height=&#34;409&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /TED3Lab-zh.github.io/media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_c51e8b6e20cb3792c8388da997b84dce.webp 400w,
               /TED3Lab-zh.github.io/media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_f1ad6b31ea975fea12975b2a231cecf6.webp 760w,
               /TED3Lab-zh.github.io/media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://tsangeyan.github.io/TED3Lab-zh.github.io/TED3Lab-zh.github.io/media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_c51e8b6e20cb3792c8388da997b84dce.webp&#34;
               width=&#34;760&#34;
               height=&#34;391&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>基于手绘草图的矢量UI图标生成</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_1/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/project/project_1/</guid>
      <description>&lt;p&gt;free-hand sketches, GAN, vectorization&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;手绘草图作为一种能够快速传递人们脑海中想法的工具, 在UI/UX设计领域中, 能够帮助设计师快速表达、交流他们的设计意图. 通常在UI图标设计的前期, 设计师们在白板上绘制低保真草图, 表达最终产品的设计原型. 然而, 在UI图标设计的实现阶段, 手绘草图仅仅扮演指导角色, 无法参与具体设计实现过程, 设计师需要借助额外的软件按照草图表达的设计意图, 从零开始制作UI设计原型. 前人的文献中尚未研究基于手绘草图直接生成UI图标设计原型, 如何将UI图标手绘草图表达的设计意图转换为矢量的、可编辑的标准UI图标是本文的研究重点. 本文提出了一种方法, 尝试缩短草图表达与具体设计过程的差距, 即基于草图表达的设计意图, 生成矢量化可编辑的UI图标雏形, 这样设计师不必从头开始制作UI图标, 而是在已有的UI图标雏形上进行修改编辑, 这能够帮助提升UI设计师的设计效率.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A study of the methods for evaluating machine generated images containing combinational creativity</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-1/</link>
      <pubDate>Mon, 23 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-1/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>Layout Generation for Various Scenarios in Mobile Shopping Applications</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-2/</link>
      <pubDate>Mon, 23 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-2/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>UI Layers Group Detector: Grouping UI Layers via Text Fusion and Box Attention</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-4/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-4/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>WikiLink: An Encyclopedia-Based Semantic Network for Design Creativity</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-2/</link>
      <pubDate>Fri, 23 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-2/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>A Study of the Exploratory Creativity Performance Between Machine and Human Designers</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-5/</link>
      <pubDate>Wed, 17 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/conference-paper-5/</guid>
      <description>&lt;!-- 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-1/</link>
      <pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-1/</guid>
      <description>&lt;!-- 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
    <item>
      <title>The Creativity Diamond—A Framework to Aid Creativity</title>
      <link>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-3/</link>
      <pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://tsangeyan.github.io/TED3Lab-zh.github.io/publication/journal-article-3/</guid>
      <description>&lt;!-- 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
  </channel>
</rss>
