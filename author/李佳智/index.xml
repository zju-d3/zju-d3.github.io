<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>李佳智 | 浙江大学-陈柳青-D3Lab</title>
    <link>https://zju-d3.github.io/author/%E6%9D%8E%E4%BD%B3%E6%99%BA/</link>
      <atom:link href="https://zju-d3.github.io/author/%E6%9D%8E%E4%BD%B3%E6%99%BA/index.xml" rel="self" type="application/rss+xml" />
    <description>李佳智</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 May 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zju-d3.github.io/author/%E6%9D%8E%E4%BD%B3%E6%99%BA/avatar_huc7354505ea04594bb3a984136900cc98_163773_270x270_fill_lanczos_center_3.png</url>
      <title>李佳智</title>
      <link>https://zju-d3.github.io/author/%E6%9D%8E%E4%BD%B3%E6%99%BA/</link>
    </image>
    
    <item>
      <title>Prototype2code:End-to-end Front-end Code Generation From UI Design Prototypes</title>
      <link>https://zju-d3.github.io/project/prototype2code/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/prototype2code/</guid>
      <description>&lt;p&gt;UI Automation, Front-end Code Generation, Design Linting, Software Engineering&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;传统的 UI 到代码的转换技术通常依赖于设计原型的质量，而这些原型的质量参差不齐，常导致生成的代码结构混乱、不支持响应式布局等问题。本研究提出的 Prototype2Code 通过整合设计原型的语法检查，针对发现的元素碎片和感知分组进行优化，提高了代码的可读性和结构清晰度。在技术实现上，Prototype2Code 应用图神经网络和大型语言模型，自动从 UI 原型中识别和分类 UI 元素，如文本、图片和列表项，并基于这些信息构建 HTML 骨架代码和 CSS 样式代码。系统支持弹性盒子（flexbox）布局模型，确保生成的代码可以适配不同设备大小。&lt;/p&gt;
&lt;p&gt;研究通过与商业代码生成平台 CodeFun 和基于 GPT-4v 的 Screenshot-to-code 系统的比较，展示了 Prototype2Code 在视觉相似度和代码质量上的优势。使用 SSIM、PSNR 和 MSE 等指标评估显示，Prototype2Code 生成的 UI 效果与设计原型的一致性最高，错误最少。此外，通过用户研究，Prototype2Code 在代码的可读性、可用性和可维护性方面均优于对比系统。Prototype2Code 系统成功地展示了在前端代码生成中整合原型整理和智能识别技术的潜力。未来工作将探索支持动态页面生成、增强与前端开发框架的兼容性，以及开发可交互的视觉平台以进一步提高工程师的操作自由度。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>基于手绘草图的矢量UI图标生成</title>
      <link>https://zju-d3.github.io/project/project_1/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_1/</guid>
      <description>&lt;p&gt;free-hand sketches, GAN, vectorization&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;手绘草图作为一种能够快速传递人们脑海中想法的工具, 在UI/UX设计领域中, 能够帮助设计师快速表达、交流他们的设计意图. 通常在UI图标设计的前期, 设计师们在白板上绘制低保真草图, 表达最终产品的设计原型. 然而, 在UI图标设计的实现阶段, 手绘草图仅仅扮演指导角色, 无法参与具体设计实现过程, 设计师需要借助额外的软件按照草图表达的设计意图, 从零开始制作UI设计原型. 前人的文献中尚未研究基于手绘草图直接生成UI图标设计原型, 如何将UI图标手绘草图表达的设计意图转换为矢量的、可编辑的标准UI图标是本文的研究重点. 本文提出了一种方法, 尝试缩短草图表达与具体设计过程的差距, 即基于草图表达的设计意图, 生成矢量化可编辑的UI图标雏形, 这样设计师不必从头开始制作UI图标, 而是在已有的UI图标雏形上进行修改编辑, 这能够帮助提升UI设计师的设计效率.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior</title>
      <link>https://zju-d3.github.io/publication/journal-article-1/</link>
      <pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/publication/journal-article-1/</guid>
      <description>&lt;!-- 
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;</description>
    </item>
    
  </channel>
</rss>
