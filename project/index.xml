<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>研究 | 浙江大学-陈柳青-D3Lab</title>
    <link>https://zju-d3.github.io/project/</link>
      <atom:link href="https://zju-d3.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>研究</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 May 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zju-d3.github.io/media/logo_huf4feb8c908596d56555fe97c8f02ec1a_564626_300x300_fit_lanczos_3.png</url>
      <title>研究</title>
      <link>https://zju-d3.github.io/project/</link>
    </image>
    
    <item>
      <title>An Artificial Intelligence Approach for Interpreting Creative Combinational Designs</title>
      <link>https://zju-d3.github.io/project/artificial-intelligence-approach/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/artificial-intelligence-approach/</guid>
      <description>&lt;p&gt;Combinational Creativity, Design Interpretation; Artificial Intelligence; Data-driven Design&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;本研究探讨了如何通过一种人工智能方法解释创意组合设计，特别是如何从设计的图像和文本描述中提取基础（base）和添加（additive）元素。通过提出一种启发式算法，结合计算机视觉和自然语言处理技术，研究有效地识别了组合创意设计中的基础和添加元素。算法的实施涵盖了多种包括判别式和生成式人工智能架构的方法。&lt;/p&gt;
&lt;p&gt;在研究中使用了专门为探索设计组合创意而制作的数据集，该数据集包括 200 种基于组合创意的产品，包括它们的名称、图像和描述。这些产品精心挑选自著名设计竞赛的获奖作品。通过对这些样本的分析，研究识别出每个产品的基础和添加元素，并验证了这些元素的准确性。研究表明，最有效的方法在识别基础元素方面达到了 87.5%的准确率，而在添加元素方面达到了 80%的准确率。&lt;/p&gt;
&lt;p&gt;此外，研究还对算法中的各个模块进行了单独分析，以评估它们在解释组合创意方面的表现。这包括使用图像识别模块来解释基础元素，以及使用实体识别和关系提取模块来从文本中提取和验证添加元素。研究中还探讨了算法在没有图像输入的情况下的表现，以及图像在解释组合创意中的作用。&lt;/p&gt;
&lt;p&gt;总体来说，这项研究通过提供一种新的计算方法来解释组合创意设计，填补了数据驱动设计周期中的一个关键空白，增强了设计过程中创意过程的理解。这不仅有助于管理和重用设计知识，加速未来设计的产生，也为设计师提供了评估和细化他们的创意方法的工具。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AutoSpark：利用感性工学和生成式 AI 来支持汽车外观设计</title>
      <link>https://zju-d3.github.io/project/autospark/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/autospark/</guid>
      <description>&lt;p&gt;Product Appearance Design Ideation, Creativity Support Tool, Generative AI&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;快速创建符合消费者情感需求的新颖的汽车外观设计是一项具有挑战的任务。最近广受欢迎的文生图模型以其出色的图像生成能力在为设计师提供灵感方面表现出极大的潜力。然而，在实际应用中，设计师仍然会面临一些问题，包括设计师与 AI 对于情感需求的定义和理解存在偏差，设计意图难以表达，模型的生成过程和生成结果难以理解和控制。在这项工作中，我们提出了一个集成了感性工学和生成式人工智能的智能交互系统，AutoSpark。它帮助设计师创造满足消费者情感需求的汽车外观设计，通过图像-图像和文本-图像的比较来迭代设计，并通过设计思维地图来管理创意过程。&lt;/p&gt;
&lt;p&gt;我们推出了 AutoSpark，这是一个集成了感性工程学和生成式人工智能的互动系统，为设计师创造满足情感需求的汽车外观设计提供创意支持。AutoSpark 采用由生成式人工智能和语义网络驱动的感性工程引擎来支持设计师进行情感词发散，情感词到设计特征的转译以及设计特征提取，从而帮助设计师实现情感需求对齐、设计意图的快速表达，并利用大语言模型根据提取出的设计特征进行提示词生成，帮助设计师快速利用文生图模型创建汽车图像。为了促进设计师对生成结果的理解和迭代，AutoSpark 利用 CLIP 模型辅助设计师对生成图像进行细粒度的相似性比较，利用 patch-inversion 算法可视化文本提示词和生成图像之间的相关性。AutoSpark 还在界面中提供了一个设计思维导图来帮助设计师高效管理设计过程。我们的用户研究表明，与基线系统相比，AutoSpark 能够有效地帮助设计师生成更符合消费者情感需求并且质量更高的汽车设计图像，同时也增强了设计师在人机共创过程中的体验。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ChatScratch:An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12</title>
      <link>https://zju-d3.github.io/project/chatscratch/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/chatscratch/</guid>
      <description>&lt;p&gt;Visual Programming Learnning, Computational Thinking, Large Language Model&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;本文介绍了 ChatScratch 系统，这是一个针对 6 至 12 岁儿童自主学习视觉编程的 AI 增强工具。随着计算思维（CT）在 K-12 教育阶段的广泛推广，传统的 CT 平台，如 Scratch，面临着适应年幼学习者的挑战。这些学习者往往缺乏进行有效学习所需的基本技能，如阅读写作能力和手眼协调能力。此外，现有的教学实践通常依赖于教师的直接指导和严格的课程结构，这对于资源有限的地区的学生来说是一大障碍。&lt;/p&gt;
&lt;p&gt;为了解决孩子们在自主使用 Scratch 时遇到的创意阻塞、创作自由度受限和缺乏编程指导等问题，我们开发了 ChatScratch。该系统利用交互式故事板和视觉提示帮助孩子们在项目规划阶段克服创意阻塞，通过集成的数字绘图和先进的图像生成技术提高创作的自由度，同时采用专门为 Scratch 设计的大型语言模型来提供编程过程中的专业指导。&lt;/p&gt;
&lt;p&gt;通过对比实验研究表明，ChatScratch 较传统 Scratch 平台在促进儿童自主编程学习方面更为有效，能够帮助儿童创作出更高质量和具有个人意义的项目。具体来说，使用 ChatScratch 的儿童在视觉元素数量、创造性支持指数和专家评分等方面都显示出了明显的提高。这些结果突显了将生成性人工智能技术与创造性活动和编程技能教育相结合的潜力，为未来在教育技术领域的应用提供了宝贵的见解。同时，研究也识别出当前系统的一些局限，并提出了未来改进和深入研究的可能方向。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DesignFusion:生成模型支持的概念设计软件</title>
      <link>https://zju-d3.github.io/project/designfusion/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/designfusion/</guid>
      <description>&lt;p&gt;Product Appearance Design Ideation, Creativity Support Tool, Generative AI&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;概念设计是产品设计和开发的一个关键阶段，包括用户需求探索和知情解决方案生成。生成模型凭借其强大的内容生成能力被应用于概念设计，为设计师的构思提供支持。然而，生成模型的生成过程缺乏透明度，生成的解决方案也比较肤浅，这些都制约了它们在复杂的概念设计任务中的表现。在本研究中，我们首先介绍了一种将生成模型与经典设计理论相结合的概念设计生成方法。该方法基于设计过程和设计属性对概念设计任务进行分解，并使用 “谁、什么、哪里、何时、为什么、如何”（5W1H）方法、“功能行为结构”（FBS）模型和 “康成工程学”（Kansei Engineering）指导生成模型通过多步推理生成概念设计解决方案。然后，我们介绍了一个使用思维导图布局来可视化多步骤推理的互动系统，名为 DesignFusion。这使设计人员能够跟踪生成过程，并控制每个推理步骤的输入/输出。两项用户研究表明，我们的方法大大提高了生成的设计方案的质量，并丰富了设计师在人机共创中的体验。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MindScratch:基于多模态生成模型的可视化编程支持工具</title>
      <link>https://zju-d3.github.io/project/bidtrainer/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/bidtrainer/</guid>
      <description>&lt;p&gt;设计教育，仿生设计，知识理解，设计推理&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;仿生设计作为跨学科类比设计的一种重要形式，为设计领域提供了许多来自生物学的创新方案。为了使设计专业学生与新手设计师等能够高效地掌握仿生设计技巧，提升他们的跨学科创新能力，我们提出了一种由大语言模型驱动的仿生设计教育方法。该方法基于一个结构化的仿生设计案例知识库，通过交互式问答帮助学习者理解结构化的仿生设计案例，并指导他们推理出新的设计方案。此外，该方法还包括对学习者设计方案的对比评估，评估基于已有案例进行，旨在进一步提升学习者的设计水平。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MindScratch:基于多模态生成模型的可视化编程支持工具</title>
      <link>https://zju-d3.github.io/project/mindscratch/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/mindscratch/</guid>
      <description>&lt;p&gt;Creativity Support Tool, Generative AI&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;编程作为培养计算思维技能的途径，已成为 K-12 教育的必要组成部分。鉴于编程的复杂性及其所需的精湛技能，现有研究已为年轻学习者提供了更易接近的编程支持工具。然而，通过我们对六位编程教育者的访谈发现，目前的编程支持工具在反映课堂学习目标、提供灵活高质量的编程指导以及支持学生创造力方面存在不足。在本文中，我们介绍了 MindScratch，这是一个基于多模态生成模型的可视化编程支持工具。MindScratch 利用交互式思维导图促进对编程过程的反思，运用针对 Scratch 精调的大型语言模型提供框架式编程支持，并集成多模态生成人工智能以增强创造力。我们的受试者内用户研究表明，MindScratch 能够支持与学习目标一致的创造性编程项目，提升代码质量和创造性，并改善编程学习体验。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prototype2code:End-to-end Front-end Code Generation From UI Design Prototypes</title>
      <link>https://zju-d3.github.io/project/prototype2code/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/prototype2code/</guid>
      <description>&lt;p&gt;UI Automation, Front-end Code Generation, Design Linting, Software Engineering&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;传统的 UI 到代码的转换技术通常依赖于设计原型的质量，而这些原型的质量参差不齐，常导致生成的代码结构混乱、不支持响应式布局等问题。本研究提出的 Prototype2Code 通过整合设计原型的语法检查，针对发现的元素碎片和感知分组进行优化，提高了代码的可读性和结构清晰度。在技术实现上，Prototype2Code 应用图神经网络和大型语言模型，自动从 UI 原型中识别和分类 UI 元素，如文本、图片和列表项，并基于这些信息构建 HTML 骨架代码和 CSS 样式代码。系统支持弹性盒子（flexbox）布局模型，确保生成的代码可以适配不同设备大小。&lt;/p&gt;
&lt;p&gt;研究通过与商业代码生成平台 CodeFun 和基于 GPT-4v 的 Screenshot-to-code 系统的比较，展示了 Prototype2Code 在视觉相似度和代码质量上的优势。使用 SSIM、PSNR 和 MSE 等指标评估显示，Prototype2Code 生成的 UI 效果与设计原型的一致性最高，错误最少。此外，通过用户研究，Prototype2Code 在代码的可读性、可用性和可维护性方面均优于对比系统。Prototype2Code 系统成功地展示了在前端代码生成中整合原型整理和智能识别技术的潜力。未来工作将探索支持动态页面生成、增强与前端开发框架的兼容性，以及开发可交互的视觉平台以进一步提高工程师的操作自由度。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TRIZGPT：一种大语言模型赋能的问题解决方法</title>
      <link>https://zju-d3.github.io/project/trizgpt/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/trizgpt/</guid>
      <description>&lt;p&gt;TRIZ 理论；大语言模型；问题解决方法；评估实验&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;TRIZ 理论，又称发明问题解决理论，是通过对大量不同领域的专利进行总结分析而提出的一种设计方法。TRIZ 提供了一系列问题解决工具和基本的问题解决框架，具有孕育创新解决方案的潜力。&lt;/p&gt;
&lt;p&gt;然而， TRIZ 理论的复杂性和抽象性对于实际应用构成了挑战。要真正实现利用 TRIZ 提出科学有效的问题解决方案，不仅要求用户深入理解 TRIZ 知识，还需要具备一定的实践经验和跨学科知识，对用户的知识水平和推理能力提出了较高的要求。随着人工智能和深度学习的发展，大语言模型（Large Language Models, LLMs）广泛的知识基础和推理能力，为解决这些挑战提供了机会。&lt;/p&gt;
&lt;p&gt;因此，本研究旨在设计和评估大语言模型增强的 TRIZ 问题解决方法。在具体研究过程中，我们首先广泛搜集并整理了 TRIZ 相关书籍和论文中的 TRIZ 应用案例，这不仅为后续实验建立了实证基础，也成为 TRIZ 研究社区宝贵的资源。随后，本研究提出了一个大语言模型赋能的 TRIZ 解决问题流程，采用分步推理和经过实验检验的提示词策略，能够利用大语言模型有效地将具体问题转化为 TRIZ 标准问题，最终输出针对发明问题的创新解决方案。最后，本研究开展了一个在机械工程领域的应用，以具体展示本方法的应用过程，同时进行了与原研究中提出的解决方案的对比。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>UI semantic component group detection:Grouping UI elements with similar semantics in mobile graphical user interface</title>
      <link>https://zju-d3.github.io/project/uisemantic/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/uisemantic/</guid>
      <description>&lt;p&gt;UI element grouping, UI object detection, UI-related software application, Transformer&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;在现代软件工程中，用户界面（UI）元素的有效组织和识别是增强应用程序交互性和功能性的关键。尽管现有的研究提出了多种 UI 元素分组的方法，但这些方法往往针对特定的软件工程任务，如 UI 测试和代码生成，而且这些分组在外观和功能上的多样性限制了其普遍适用性。&lt;/p&gt;
&lt;p&gt;本文提出了一种新的 UI 语义组件分组方法，旨在通过深度学习技术提高 UI 元素分组的普适性和效率。该方法使用改进的 Deformable-DETR 模型，结合 UI 元素颜色表示和组分布学习，从而能够识别出具有相似语义的 UI 元素组。此外，所提出的 UISCGD 模型不仅提升了分组的检测性能，还能支持多种 UI 相关的软件工程任务，如感知组检索、代码结构优化及为屏幕阅读器生成可访问性数据。&lt;/p&gt;
&lt;p&gt;通过在 1988 个不同移动应用的 GUI 截图上的训练与测试，UISCGD 模型在对象检测性能上达到了 77.5%的高精度，显著优于其他现有的 SOTA 模型。此外，通过一系列的实证研究，证实了该模型在感知组生成、UI 代码自动生成和生成屏幕阅读器的可访问性数据等方面的应用效果。UISCGD 模型的成功应用展示了深度学习技术在 UI 元素分组领域的巨大潜力。该研究不仅提高了 UI 元素分组的准确性和通用性，还为未来在不同平台和设备上的 UI 设计和开发提供了有力的技术支持。未来的工作将探索如何进一步提高模型的泛化能力，并扩展到更多的 UI 设计和开发场景中。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/ui_seg_hu6d7c10947a9d3f7a2b5706f7f9bfaa1c_21864_1a42aa512b9b7eab6ff03d710c08917f.webp 400w,
               /media/ui_seg_hu6d7c10947a9d3f7a2b5706f7f9bfaa1c_21864_c04847a84e3608569bd83b7526a3d687.webp 760w,
               /media/ui_seg_hu6d7c10947a9d3f7a2b5706f7f9bfaa1c_21864_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/ui_seg_hu6d7c10947a9d3f7a2b5706f7f9bfaa1c_21864_1a42aa512b9b7eab6ff03d710c08917f.webp&#34;
               width=&#34;580&#34;
               height=&#34;410&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>UI设计稿智能检查与校正</title>
      <link>https://zju-d3.github.io/project/project_3/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_3/</guid>
      <description>&lt;p&gt;UI design lint, UI to code, multimodal feature fusion, object detection&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;UI设计稿零碎图层合并：Imgcook 是阿里巴巴旗下以各种设计稿图像 (Sketch/PSD/静态图片）为原材料烹饪的匠心大厨，通过智能化手段将各种原始设计稿一键生成可维护的 UI 视图代码和逻辑代码。在实际生产设计过程中，为了达到想要的视觉效果，设计师会使用多个零碎图层来表达一个UI组件。这种设计方式会对智能代码生成算法造成干扰，从而影响最终生成代码的质量。为了保证智能代码生成算法能够生成高质量的代码，亟需有着更高设计标准的设计稿，但这必定会增加设计师的工作成本。由此可见，一个用于检测设计稿中存在的零碎图层并将其自动合并为UI组件的智能检查工具，能够有效解决从设计稿为输入的代码生成质量低下的问题。传统的图层合并方法，通常采用人工辅助合并或一些基于启发式的检查规则来判断是否对这些图层进行合并。这类方法过于依赖设计师或开发者的判断，同时对大量图层进行筛选和判断也提高了工作时间成本。目前尚无方法，通过端到端的智能检测算法，自动筛选和合并碎片图层成为UI组件，来提高最终代码生成的质量。本项目与阿里巴巴智能化前端团队合作，致力于研究智能化端到端的图层合并方法。&lt;/p&gt;
&lt;p&gt;UI设计稿图文同语义成组：随着移动应用程序的普及和发展，图形用户界面（GUI）有着巨大的开发需求。从UI设计稿自动生成UI代码极大地简化了开发流程。但是，设计稿中的嵌套层结构会影响生成代码的质量和可用性。现有的GUI自动化技术很少能检测和分组嵌套层以提高生成代码的可访问性。在本文中，我们提出了一种基于计算机视觉的方法UI Layers Grouper。它可以自动检测呈现相同语义含义的图像（即基本形状和视觉元素）和文本层。我们提出了两个组件，文本融合和框注意力机制，它们利用来自设计稿的文本信息作为先验组定位信息。我们构建了一个用于训练和测试的大规模 UI 数据集，并提出了一种数据增强方法来提高检测性能。实验表明，所提出的方法在层分组方面取得了不错的准确性。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_9ded980b4a5bc6c0b35870890b568003.webp 400w,
               /media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_320200b6f7b3845f8f4dbd128cbb0c05.webp 760w,
               /media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_3_hub2c971b0630d2fc05a78aa3ea5ec349c_1664053_9ded980b4a5bc6c0b35870890b568003.webp&#34;
               width=&#34;760&#34;
               height=&#34;371&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>基于结构化知识的仿生设计创意激发工具</title>
      <link>https://zju-d3.github.io/project/project_6/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_6/</guid>
      <description>&lt;p&gt;Bio-inspired design, Design ideation, Information extraction&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;经过数百万年的进化，自然系统中的许多优秀的生物策略可以被利用到一种新的类比设计形式中，即生物启发设计（BID）。尽管BID作为一种设计方法已被证明是有益的，但在生物学和工程学之间存在着差距，因为绝大多数的生物知识都是非结构化的。这种非结构化的生物知识通常以大段的形式呈现。设计者很难快速获取和理解非结构化生物知识中的关键信息。为了解决这个问题，我们提出了一种结构化生物知识的方法，并构建了AsknatureNet：一个基于结构化知识的仿生设计创意激发工具。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_70e177ab67fc5c7e3e6e308480ceac82.webp 400w,
               /media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_5b3c8251c8362b6bc80a8ba81c126f72.webp 760w,
               /media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_6_hu9352064ea92aef2c948827f29c01622a_241556_70e177ab67fc5c7e3e6e308480ceac82.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>电商AR新交互新体验探索</title>
      <link>https://zju-d3.github.io/project/project_4/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_4/</guid>
      <description>&lt;p&gt;augmented reality, virtual reality, online shopping, comparison of technologies, 3D / Multimodal user interface&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;随着元宇宙概念的持续升温和社交、生产协作、购物等具体应用场景的逐步构建，各类产业对于扩展现实系列技术的体验设计规范、针对具体场景的技术引入和体验优化等方面的需求正在扩大。另一方面，学界与业界对于虚拟现实、增强现实、混合现实等各类主流元宇宙用户界面技术的基本定义、技术特征、对用户体验的具体影响的共识尚未建立；高维度、多感官通道的扩展现实体验空间的设计空间与设计规范有待拓展；适合扩展现实体验空间的具体设计策略与呈现内容的典型形式、方式有待探索。本项目依托浙江大学与阿里巴巴前端设计委员会合作项目开展，通过扩展现实技术创新电商平台的营销导购方式，实现基于多种扩展现实技术的场景化购物方案和原型设计。项目下辖多个研究小组，在增强现实与虚拟现实技术的用户体验差异、扩展现实场景下的多模态信息呈现技术、面向特殊使用场景的下一代扩展现实技术技术特征等方面做出有力的探索，并结合场景特点提出以场景作为商品配置的货架、以互动塑造商品认知过程、以三维多感官界面重塑界面信息架构的研究思路。相关研究成果可应用于虚拟购物平台三维化营销场景的设计实践，或为一般扩展现实应用的信息与交互设计提供指导。该团队目前参与元宇宙相关主题《信息与交互设计》课程建设及多个本科生科研训练项目过程指导。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_df309c55cf4e9b685b47ad60ad2adfcc.webp 400w,
               /media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_efdf3b692817c68c53bca692f1ead846.webp 760w,
               /media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_4_huc72469f99a3f3f8541383a1eb9361199_766803_df309c55cf4e9b685b47ad60ad2adfcc.webp&#34;
               width=&#34;760&#34;
               height=&#34;374&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;











&lt;div class=&#34;gallery&#34;&gt;

  
  
  
    
    
    
    
    
    &lt;a data-fancybox=&#34;gallery-project_4&#34; href=&#34;https://zju-d3.github.io/media/albums/project_4/1.png&#34; &gt;
      &lt;img src=&#34;https://zju-d3.github.io/media/albums/project_4/1_hu90bce225f99162c83f1cec892628d724_418761_520x0_resize_q75_h2_lanczos_3.webp&#34; loading=&#34;lazy&#34; alt=&#34;1.png&#34; width=&#34;520&#34; height=&#34;321&#34;&gt;
    &lt;/a&gt;
  
    
    
    
    
    
    &lt;a data-fancybox=&#34;gallery-project_4&#34; href=&#34;https://zju-d3.github.io/media/albums/project_4/4.png&#34; &gt;
      &lt;img src=&#34;https://zju-d3.github.io/media/albums/project_4/4_hu3168de5f82c083371df3b72e366723b7_9510081_520x0_resize_q75_h2_lanczos_3.webp&#34; loading=&#34;lazy&#34; alt=&#34;4.png&#34; width=&#34;520&#34; height=&#34;520&#34;&gt;
    &lt;/a&gt;
  

&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>电商导购场中用户浏览行为意图预测</title>
      <link>https://zju-d3.github.io/project/project_7/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_7/</guid>
      <description>&lt;p&gt;E-commerce, Product recommendation page, Intent prediction, Interest Analysis&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;用户行为数据一直是电商平台决策和提升体验的关键，尤其是在预测用户行为意图时。如今，随着推荐系统的普及，电商导购场(PRP)在电子商务平台中发挥着越来越重要的作用。然而，过去关于跨电子商务平台预测用户行为意图的研究可能不适用于用户具有不同特征的电商导购场。本研究对电商导购场的用户浏览行为意图进行了研究和预测。收集和处理了电商导购场的大量用户数据，并建立了相应的数据集。在此基础上，提出了一种用户兴趣分析方法，并对五种浏览意图预测模型进行了应用和比较。该方法区分了不同浏览兴趣程度的用户，模型能更好地预测用户在不同兴趣群体中的浏览行为意图。在大规模数据集上的验证实验表明，该方法能够较好地预测用户的浏览意图。我们探索人工智能（AI）的最新发展，使用预先训练好的语言模型（PLM）来微调3个模型，并总结出生物知识的关键词。&amp;ldquo;来源&amp;rdquo;、&amp;ldquo;好处 &amp;ldquo;和 &amp;ldquo;应用&amp;rdquo;。我们评估了这些关键词与生物知识的相关性，结果表明，该模型具有与人类相同的概括能力。基于这些关键词，我们构建了一个用于刺激BID构思的语义网络，提出了一个基于语义网络的构思算法，并开发了AsknatureNet。AsknatureNet可以实现解决方案驱动的模式BID和问题驱动的模式BID。每种模式都会产生3种不同程度的结果。通过两个案例研究，我们证明了将该系统用于解决方案驱动的模式BID和问题驱动的模式BID的有效性，并产生了解决问题和开放创新的新设计理念。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_90ded84e83fdb18b7cf7d0bf258a0e13.webp 400w,
               /media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_b6cf7780c5cb79821ddda234ff8b7d79.webp 760w,
               /media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_7_hu23f9a738b3f445247a93ef5c5b05aed9_217399_90ded84e83fdb18b7cf7d0bf258a0e13.webp&#34;
               width=&#34;760&#34;
               height=&#34;146&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>电商平台中不同购物场景下的布局生成</title>
      <link>https://zju-d3.github.io/project/project_2/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_2/</guid>
      <description>&lt;p&gt;布局生成，深度生成模型，用户界面设计，商品展示页面&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;布局是移动购物应用程序的商品展示页面中至关重要的一部分。为了清楚、准确地传达消费者所需的商品信息，商品展示页面（Product Listing Pages, PLP）的布局设计通常由其购物场景驱动。在这项工作中，我们研究了针对不同场景的布局设计，并提出了一个设计空间来指导PLP的布局生成和评估。此外，我们还提出了一个布局生成模型，LayoutVQ-VAE，该模型以用户输入的布局应用场景和元素类别为约束，能够生成满足约束的高质量布局。LayoutVQ-VAE也可以应用于文档布局、杂志布局、手机UI布局等相关的设计任务中。&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://zju-d3.github.io/project/project_2/Layout%20Generation%20for%20Various%20Scenarios%20in%20Mobile%20Shopping%20Apps.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;</description>
    </item>
    
    <item>
      <title>维基智联：基于维基百科的创意激发语义网络</title>
      <link>https://zju-d3.github.io/project/project_5/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_5/</guid>
      <description>&lt;p&gt;Semantic network, Design innovation, Wikipedia, Data-driven design, Data-driven ,innovation&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;数据驱动的设计和创新是一个重新使用和提供有价值和有用信息的过程。然而，现有的用于设计创新的语义网络是建立在仅限于技术和科学信息的数据源上。此外，现有的研究只在统计学或语义学关系上建立语义网络的边缘，这不太可能充分利用这两类关系的好处，发现设计创新的隐性知识。因此，我们构建了WikiLink，一个基于维基百科的语义网络。在WikiLink中引入了融合了概念间统计学和语义学权重的组合权重，并开发了四种算法来激发新的想法。进行了评估实验，结果显示该网络的特点是对术语、关系和学科的高度覆盖，这证明了该网络的有效性和有用性。然后，一个演示和案例研究结果表明，WikiLink可以作为概念设计创新的想法生成工具。WikiLink的源代码和后台数据是开源的，供更多的用户探索和使用。&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_f75a847c0fbb640851c3c1f450a96d76.webp 400w,
               /media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_165c867c97f947219768745f2ae65d47.webp 760w,
               /media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_5_1_hu6902b2d5780de135a05348974029a600_220412_f75a847c0fbb640851c3c1f450a96d76.webp&#34;
               width=&#34;760&#34;
               height=&#34;409&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_c51e8b6e20cb3792c8388da997b84dce.webp 400w,
               /media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_f1ad6b31ea975fea12975b2a231cecf6.webp 760w,
               /media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://zju-d3.github.io/media/project_5_2_hu732c0e914b6a87f351ee1d07fb385e6c_89035_c51e8b6e20cb3792c8388da997b84dce.webp&#34;
               width=&#34;760&#34;
               height=&#34;391&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>基于手绘草图的矢量UI图标生成</title>
      <link>https://zju-d3.github.io/project/project_1/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://zju-d3.github.io/project/project_1/</guid>
      <description>&lt;p&gt;free-hand sketches, GAN, vectorization&lt;/p&gt;
&lt;h2 id=&#34;项目简介&#34;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;手绘草图作为一种能够快速传递人们脑海中想法的工具, 在UI/UX设计领域中, 能够帮助设计师快速表达、交流他们的设计意图. 通常在UI图标设计的前期, 设计师们在白板上绘制低保真草图, 表达最终产品的设计原型. 然而, 在UI图标设计的实现阶段, 手绘草图仅仅扮演指导角色, 无法参与具体设计实现过程, 设计师需要借助额外的软件按照草图表达的设计意图, 从零开始制作UI设计原型. 前人的文献中尚未研究基于手绘草图直接生成UI图标设计原型, 如何将UI图标手绘草图表达的设计意图转换为矢量的、可编辑的标准UI图标是本文的研究重点. 本文提出了一种方法, 尝试缩短草图表达与具体设计过程的差距, 即基于草图表达的设计意图, 生成矢量化可编辑的UI图标雏形, 这样设计师不必从头开始制作UI图标, 而是在已有的UI图标雏形上进行修改编辑, 这能够帮助提升UI设计师的设计效率.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
